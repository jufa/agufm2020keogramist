<html>
  <head>
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      AGU Fall 2020 Poster: Keogramist: Explore 1400 Nights of Aurora on a Phone
    </title>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed&display=swap" rel="stylesheet">
  </head>
  <style>
    :root {
      --hilite: gold
    }
    body {
      box-sizing: border-box;
      font-family: 'Roboto Condensed', sans-serif;
      background-color: #222;
      color: #ddd;
      font-weight: normal;
      padding: 0;
      margin: 0;
      font-size: 18px;
    }
    a {
      color:deepskyblue;
    }
    b {
      color: var(--hilite);
    }
    a:active {
      color: white;
    }
    a:visited {
      color:mediumorchid;
    }
    a:hover {
      color: white;
    }
    h1 {
      text-align: center;
      font-size: 3em;
      border-left: 20px solid var(--hilite);
      margin-left:-20px;
    }
    h2 {
      font-size: 2em;
      color:var(--hilite);
      border-left: 20px solid var(--hilite);
      margin-left:-20px;
      padding-left: 10px;
    }
    h3 {
      font-size: 1.3em;
      color:var(--hilite);
      margin-bottom: 5px;

    }
    h1, h2, h3, h4, h5 {
      font-weight: normal;
    }

    img {
      box-sizing: border-box;
      display: block;
      max-width: 100%;
      max-height: 400px;
      width: auto;
      height: auto;
      margin: 0 auto;
      padding-bottom: 0;
      border: 1px solid #777;
    }
    figure {
      max-width: 600px;
      width: auto;
      height: auto;
      margin: 20px auto;
      background-color: #555;
      box-shadow: 0px 5px 10px #444;
    }
    figure img {
      margin-bottom: 20px;
    }
    figcaption {
      line-height: 1.2em;
      max-width: 500px;
      font-style: italic;
      font-size: 0.9em;
      padding: 0 20px 20px 20px;
    }
    li {
      margin-bottom: 1em; 
      line-height: 1.4em;
    }
    p {
      line-height: 1.4em;
    }
    p.summary {
     font-size: 1.2em;
     line-height: 1.2em; 
    }
    #main {
      display: block;
      max-width: 640px;
      padding: 20px;
      background-color: #444;
      margin: 0 auto;
      box-shadow: 0px 0px 20px #000;
    }
    .authors {
      display: block;
      text-align: center;
      max-width: 400px;
      margin: 0 auto;
      margin-bottom: 20px;
    }
    .session {
      display: block;
      text-align: center;
      max-width: 400px;
      margin: 10px auto;
      color: #999;
    }
    .video_wrapper {
      margin-top: 20px;
      position: relative;
      padding-bottom: 56.25%; /* 16:9, for an aspect ratio of 1:1 change to this value to 100% */ 
    }
    .video-embed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
    .big-link {
      display: block;
      text-align: center;
      margin: 0 auto;
      font-size: 1.2em;
      margin: 10px 0;
    }
    @media screen and (max-width: 600px) {
      body {
        font-size: 18px;
      }
    }
  </style>
  <body>
    <div id="main">
      <h1>Keogramist: Explore 1400 Nights of Aurora on a Phone</h1>
      <p class="authors">Jeremy Kuzub (Jufa Intermedia), Dr. Elizabeth MacDonald (NASA Goddard Space Flight Center)</p>
      <p class="session">AGU Fall Session 2020</p>
      <p class="session">Author contact: <a href="mailto:jeremy@jufaintermedia.com">jeremy@jufaintermedia.com</a></p>
      <div class="video_wrapper">
        <iframe class="video-embed" src="https://www.youtube.com/embed/BFbtJovC7XQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
      <p class="big-link"><a href="https://www.youtube.com/watch?v=BFbtJovC7XQ">Watch a video walkthrough of Keogramist here</a></p>
      <p><a href="https://keogramist.com" target="pipeline"><img loading=lazy src="./image/app4.jpg"/></a></p>
      <p class="big-link"><a href="https://keogramist.com" target="pipeline">Try the Keogramist app here</a></p>
     
      <h2>Abstract</h2>
        <p>The aurora research community has made full-colour all-sky camera (ASC) imagery available online for public outreach and education, providing a deep resource of archival material. Concurrently, modern mobile devices like smartphones have improved in capability, able to present interactive video and 3D content directly in web browsers. This work represents an example of citizen science in which  an individual from another field repurposed, or "MacGyvered", existing AuroraMAX ASC timelapse archive, to make over 1400 nights of aurora activity more engaging and immersive for users of mobile devices. The resulting "Keogramist" web app is designed to be a visually intuitive gateway to explore and experience auroral activity. An "enhanced stacked keogram" interface organizes aurora activity temporally, and enhances visible features using minor image processing. Users can choose any night's keogram and replay and interact with the corresponding timelapse ASC video from a first-person perspective, emulating what a viewer would experience standing under the aurora and looking at the sky around them. Adjustable parameters can accommodate a range of existing ASC resolutions, fields of view, and replay rates, allowing other ASC archives to be explored in the same way. Scientific and public users alike may find the format beneficial as it provides quick, mobile review for events of interest. This platform may enable citizen scientists to interact with large amounts of data for image and feature characterization.</p>

      <h2>Motivation and Background</h2>
      <h3>A 'Human' viewpoint of aurora video</h3>
      <ul>
        <li>Help as many people as possible explore existing aurora borealis all-sky camera (ASC) timelapse archive using common platforms and low-barrier technology</li>
        <li>Make a more intuitive visual search interface to rapidly locate nights with activity of interest and filter out nights with poor viewing conditions</li>
        <li>Create an immersive, first person viewpoint, as if the user were standing in the same place as the ASC</li>
        <li>Allow the user to look around this virtual environment, access specific moments of the nights activity, and share specific moments with others using a standard URL</li>
      </ul>
      <figure>
        <img loading=lazy src="./image/asi-annotated.jpg"/>
        <figcaption>A typical All-Sky camera for automated monitoring of aurora. Although many cameras are designed specifically to gather calibrates, wavelength filtered data, some are used as outreach and education tools, using standard consumer fish-eye lenses and digital SLRs imaging on Bayer-pattern RGB sensors. This public facing data is often compressed into lossy timelapse video, since specific calibrated measurements are not needed.</figcaption>
      </figure>
      <figure>
        <img loading=lazy src="./image/all_sky_camera_animated_640x480.gif"/>
        <figcaption>All sky camera view of aurora substorm overhead in Yellowknife, NWT (AuroraMAX). While an all-sky camera timelapse is intriguing, it is not the same for a viewer as being in the presence of aurora and using their own intuition (eyes, ability to pivot and look around)</figcaption>
      </figure>
      <figure>
        <img loading=lazy src="./image/planetarium.jpg"/>
        <figcaption>Inspiration: ASC camera data can be reprojected to make a more immersive experience, as planetariums discovers a long time ago</figcaption>
      </figure>
      <figure>
        <img loading=lazy src="./image/enterdome.gif"/>
        <figcaption>Early prototype: what if we make a virtual online planetarium to make existing aurora ASC timelapses more immersive, using the same projection concept? This animation shows a viewpoint of walking into such a virtual space from the outside. The projected video can be seen on both inside and outside surface of the dome for debugging</figcaption>
      </figure>
      
      <h3>Keograms as an 'accessible' visual index of night sky activity</h3>
      <figure>
        <img loading=lazy src="./image/keogram_animation_480x720_128f 100ms.gif"/>
        <figcaption>"Keograms" stack the center column of consecutive ASC frame from left-to-right in an image, to give an overview of an entire night's sky activity at a glance, rather than parsing through hours of video</figcaption>
      </figure>
      <figure>
        <img loading=lazy src="./image/keogram_annotated_a_20200525a.jpg"/>
        <figcaption>The relation of a keogram to the all sky camera and time of night is intuitive enough to be understood with a little instruction</figcaption>
      </figure>
      <figure>
        <img loading=lazy src="./image/keogram_annotated_c_20200525a.jpg"/>
        <figcaption>Citizen scientists and those interested in aurora have shown in a survey to readily understand keogram relationships to 'interesting' nights of aurora activity</figcaption>
      </figure>

      <h2>Implementation and performance</h2>
      <p><a href="pipeline.html"><img loading=lazy src="./image/pipeline_1000p.jpg"/></a></p>
      <p class="big-link"><a href="pipeline.html">Enlarge workflow diagram</a></p>

      <h3>Keogram & metadata generation</h3>
      <p class="summary">Offline extraction of timecodes and keogram images directly from existing MP4 video was successful</p>
      <ul>
        <li>Generating Keograms from compressed MP4 video was still found to be a high enough quality for visual inspection and differentiation of substorms, weather, red, green, and magenta aurora colours</li>
        <li>Extracting timestamp data using a machine vision library (PyTesseract) from MP4 ASC camera data was found to be reliable if the algorithm discarded corrupt results and simply tried adjacent video frames</li>
        <li>Using a series of command-line driven Python scripts allowed the process to be flexible enough to run on a schedule and via automation files</li>
        <li>Using JSON data format for all metadata in a single file was found to compress well for across-web loading, and allowed organic extension of metadata. Client devices were found to have more than enough memory to allow local parsing and search of this data, even for 1400 night-entries, each with 8 or more variables (keys)</li>
      </ul>

      <h3>Keogram index</h3>
      <p class="summary">A visually searchable HTML/Javascript index of 1400 nights of keograms and Kp data was performant on smartphones</p>
      <ul>
        <li>Keogram interface could load efficiently over mobile data, caching of images worked on standard web platforms, making revisits quick to load</li>
        <li>Progressive loading of Keograms, allowed the interface to remain responsive, breaking approximately 35MB of keogram resources into 20-30KB sized chunks</li>
        <li>Time-aligning 3-hour Kp as a colour-coded heat-map appeared intuitive and visually highlighted nights of higher geomagnetic activity</li>
        <li>Scaling and aligning my time and local midnight allowed comparison of activity around midnight, and differentiation between longer and short nights (and videos)</li>
        <li>Vertically arranged interface was suitable for all screen sizes and platforms tested (since vertical scrolling is a 'natural' web activity for progressive reveal of information)</li>
      </ul>
      <h3>AuroraDome viewer</h3>
      <p class="summary">Hardware-accellerated 3D rendering in browsers was suitable for real time re-projection of ASC video</p>
        <ul>
          <li>Between 30 and 60 frames per second performance on mobile and desktop computers</li>
          <li>Works the same way on current modern, major browsers, due to web standards compliance for hardware-accelerated WebGL 3D</li>
          <li>JavaScript-based 3D rendering using Three.js was found to be performant when reprojecting 1080p video directly from AuroraMAX host servers</li>
          <li>buffering, playback rate and seeking behaviours were slightly different across browsers, but taking this into account made a consistent interface</li>
          <li>dynamically selecting video file based on screen resolution increased loading performance without compromising perceived quality (i.e. 1080p for large screen, 480p for smaller mobile screens)</li>
          <li>Projecting the video as a texture on a geometry (i.e. a hemisphere) provided the desired effect of a 'planetarium' or 'skydome' view</li>
          <li>Warping the skydome mesh vertices was an effective way of compensating for various non-ideal ASC lens distortion effects, especially near the extreme horizon</li>
          <li>Most ASC lens projection transforms tested conformed approximately to the 'equidistant' model, i.e. r = f θ, where video pixel distance from the center of the camera sensor (and therefore video frame) f has a linear relationship to angle θ from the zenith</li>
          <li>The extreme edges of the ASC video capture tended to be occluded by local buildings, foliage, and even light pollution or protective dome distortion, so a virtual background forest was added to obscured these artifacts and maintain the immersive illusion</li>
          <li>Adding information such as compass and time data as unobtrusive elements also helped maintain the immersive illusion</li>
          <li>Although most ASC timelapse is in the 4-10 second cadence, testing with 24 frame-[per-second real time video was also performant, and provided some addition 'reality' due to smoother motions</li>
          <li>Although 1080p is a standard 'high' resolution video, 4K resolution would be more suited to skydome applications (i.e. 4 times the pixel count)</li>
          <li>Rather than re-encode existing video to fit the AruraDome viewer, it was found to be more suitable to have the viewer do all the work in real time, since Three.js is optimized to map video textures onto the virtual dome geometry using the hardware graphics acceleration and dome vertex locations</li>
          <li>Building the AuroraDome viewer as a separate web app that receives parameters from the web address URL parameters makes sharing a specific moment in a specific night (and camera and replay parameters) much easier, and independent of any separate indexing system. This makes AuroraDome suitable for any suitable ASC video data of appropriate format.</li>
        </ul>
      
      <h2>What did we learn?</h2>
      <p class="summary">Users often ignore instructions, just want to start searching and experiencing. About 50% use smartphones.</p>
      <h3>User survey</h3>
      <ul>
        <li>Users from the Alberta Aurora Chaser Group and the Royal Astronomical Society of Canada (Ottawa Chapter) were surveyed about their experience testing the app.</li>
        <li>Users were evenly divided between smartphone and desktop platforms, as well as frequency of seeing aurora in person, from never through often.</li>
        <li>The survey responses indicated they were able to use the Keogramist index and AuroraDome viewer to find and experience interesting aurora video, and that they would use the app again.</li>
        <li>A significant number of users did not read the introduction or instructions, leading to some confusion later on (i.e. asking for features that were discussed in the onboarding) . This indicated that any guidance or instructions should be inline and cue the user, rather than front load context or direction</li>
      </ul>
      <figure>
        <img loading=lazy src="./image/surveyresults.png"/>
        <figcaption>Survey results from Alberta Aurora Chasers Facebook Group and Royal Astronomical Society of Canada (Ottawa) volutneers. Not reading the directions is a common issue in web-based interactives, so inline-familiarization is often prefereable. Most respondents answered they would use the app again or share it.</figcaption>
      </figure>
      
      <h3>Other findings</h3>
      <p class="summary">Researchers, citizen scientists, and enthusiasts used the app</p>
      <ul>
        <li>Web-based applications proved robust and performant on a variety of mobile consumer computing platforms using standard web browsers. No special server-side software or client side platform specific "App" were required</li>
        <li>Researchers can also use this interface for quick mobile review of data, particularly for events of interest, e.g. substorms which are easily identified. </li>
        <li>It was found that minor image processing (saturation enhancement) enhances the visibility of aurora features in keograms features, specifically different emission wavelengths). This is documented to maintain scientific integrity.</li>
        <li>The app has been accessed hundreds of times in the starting February 2019 by aurora chasers and citizen scientists across the globe, with specific interest coming from the Royal Astronomical Society of Canada members, and Facebook groups such as Alberta Aurora Chasers.</li>
      </ul>
      <h2>Implications & next steps</h2>
      <p class="summary">Citizen science is multidisciplinary. Next steps include more cameras, more search filters, ability to tag specific events</p>
        <ul>
          <li>This work represents an example of citizen science, in which an individual from one field (in this case computer vision and mobile web architectures) mades a new contribution to a different domain (visual aurora research)</li>
          <li>This platform may enable citizen scientists to interact with vast amounts of data for image and feature characterization, similar to the Zooniverse platform efforts. </li>
          <li>The work is being highlighted by the Aurorasaurus citizen science project to guide the applicability and broadcast to interested users</li>
          <li>This interface has also shown promise for additional filters, for example adding additional filtering of nights by Kp or computer-vision based ranking metrics. These sorts of features have also been requested in user feedback</li>
          <li>Within reasonable constraints, the AuroraDome viewer is agnostic of the specific ASC video source, framerate, resolution, and projection type, for example real-time video</li>
          <li>The interface has demonstrated a performant and usable platform on mobile and desktop browsers, without the need to visit and App store or install software</li>
        </ul>

      <h2>References</h2>
        <p><a href="https://www.researchgate.net/publication/23914035_Plasma_Injection_at_Synchronous_Orbit_and_Spatial_and_Temporal_Auroral_Morphology">Plasma Injection at Synchronous Orbit and Spatial and Temporal Auroral Morphology R. H. Eather, S. B. Mende, R. J. R. Judge</a></p>
        <p><a href="https://www.perficient.com/insights/research-hub/mobile-vs-desktop-usage-study">Mobile vs. Desktop Usage in 2019, retrieved November 2, 2020</a></p>
        <p><a href="https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/Introduction">Introduction to Progressive Web Apps, retrieved November 2, 2020</a></p>
        <p><a href="https://innovis.cpsc.ucalgary.ca/Publications/_LayImmersive2016">Slicing the Aurora, Sebastian Lay et al.</a></p>
        <p><a href="https://drive.google.com/file/d/1VgllCa3dyJ6OkbzSwZGIybNQJNwEGPhM/view">The Development of the Auroral Substorm" S.-I. Akasofu</a></p>
        <p><a href="https://www.asc-csa.gc.ca/eng/astronomy/auroramax/default.asp">The AuroraMAX website</a></p>
        <p><a href="https://data-portal.phys.ucalgary.ca/home/">Data portal at the University of Calgary Auroral Imaging Group data portal</a></p>
        <p>Conversation with Dr. Don Hampton, University of Alaska, Fairbanks, May 21, 2020</p>
        <p>Online survey directed to Alberta Aurora Chasers Facebook Group and Royal Astronomical Society of Canada (Ottawa Chapter) November 2020</p>

      <h2>Acknowledgements</h2>
        <h3>Special thanks to:</h3>
        <p>Dr. Eric Donovan, Dr. Emma Spanswick, and Darren Chaddock at the University of Calgary Auroral Imaging Group</p>
        <p>Dr. Don Hampton at the University of Alaska, Fairbanks, Geophysical Institute</p>
        <p>The Royal Astronomical Society of Canada (RASC) Ottawa Chapter</p>
        <p>The Alberta Aurora Chasers Group</p>
        <p>Laura Brandt of Aurorasaurus</p>
        <p>Alan Dyer of RASC Calgary Chapter</p>
      </div>
  </body>
</html>
